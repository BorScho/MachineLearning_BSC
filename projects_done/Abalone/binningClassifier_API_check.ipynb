{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to follow these recommendations: https://scikit-learn.org/stable/developers/develop.html#rolling-your-own-estimator <br>\n",
    "I could not get the BinningClassifier to fullfill all the requirements that are checked by scikits check_estimator-test-suite. <br>\n",
    "Read more on this here: https://scikit-learn.org/stable/modules/generated/sklearn.utils.estimator_checks.check_estimator.html#sklearn.utils.estimator_checks.check_estimator <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "from sklearn.utils.validation import check_is_fitted, check_array, check_X_y\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import numpy as np\n",
    "\n",
    "class BinningClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    A wrapper around a regression-estimator that converts the output of the regressor into a classification-statement.\n",
    "    This is done by separating the output-range of the regressor into bins (given by intervals as a user input). \n",
    "    The BinningClassifier returns the number/ index of the bin in which the regressor-output lies, starting with 0.\n",
    "    This wrapper-class around a regressor is necessary to be able to use the regressors in grid-search etc.:\n",
    "    e.g. from the GridSearchCV documentation:\n",
    "    [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html]\n",
    "    class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, ...)\n",
    "    Parameters:\n",
    "        estimator: estimator object\n",
    "        This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a score function, or scoring must be passed.\n",
    "    \"\"\"\n",
    "\n",
    "    # scikit-learns check_estimator from sklearn.utils.estimator_checks seems to have a problem with this constructor's kwargs argument:\n",
    "    \"\"\" \n",
    "    \n",
    "    def __init__(self, regressor=None, intervals=None, **regressor_params):\n",
    "        if regressor and regressor_params:\n",
    "            regressor.set_params(**regressor_params)\n",
    "                  \n",
    "        self.regressor = regressor\n",
    "        self.intervals = intervals\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, regressor=None, intervals=None):\n",
    "        self.regressor = regressor\n",
    "        self.intervals = intervals\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # Validate and check X and y for consistency,deny sparse X, \n",
    "        X, y = check_X_y(X, y, accept_sparse=False, y_numeric=True, ensure_2d=True)\n",
    "        \n",
    "        # Check if the intervals are provided\n",
    "        if self.intervals is None or not isinstance(self.intervals, np.ndarray) or not len(self.intervals) >= 2:\n",
    "            raise ValueError(\"Intervals must be provided as a numpy array.\")\n",
    "        \n",
    "        # Check if the regressor is provided\n",
    "        if self.regressor is None or not isinstance(self.regressor, RegressorMixin):\n",
    "            raise ValueError(\"A valid scikit-learn regressor must be provided.\")\n",
    "                \n",
    "        # Fit the regressor\n",
    "        self.regressor.fit(X, y)\n",
    "        \n",
    "        # Define the array of possible class-attributes:\n",
    "        self.classes_ = np.arange(len(self.intervals) - 1)\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # Ensure that the fit was successful\n",
    "        try:\n",
    "            check_is_fitted(self, ['regressor', 'intervals', 'classes_'])\n",
    "        except NotFittedError as exc:\n",
    "            print(\"Model is not fitted yet.\")\n",
    "\n",
    "        # Ensure X is a 2d array (i.e. has 2 axises) and denies sparse data\n",
    "        X = check_array(X, accept_sparse=False, ensure_2d=True)\n",
    "\n",
    "        # Predict using the regressor\n",
    "        reg_predictions = self.regressor.predict(X)\n",
    "        \n",
    "        # Determine the interval index for each prediction - subtract 1 because np.digitize counts from 1 not 0\n",
    "        classes = np.digitize(reg_predictions, bins=self.intervals, right=True) - 1\n",
    "        \n",
    "        return classes\n",
    "    \n",
    "\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        # Ensure that the fit was successful\n",
    "        try:\n",
    "            check_is_fitted(self, ['regressor', 'intervals', 'classes_'])\n",
    "        except NotFittedError as exc:\n",
    "            print(\"Model is not fitted yet.\")\n",
    "        \n",
    "        binned_predictions = self.predict(X)\n",
    "        \n",
    "        # Create the probability array:\n",
    "        num_samples = len(binned_predictions)\n",
    "        num_classes = len(self.classes_)\n",
    "        proba = np.zeros((num_samples, num_classes))\n",
    "        \n",
    "        # Assign probabilities based on class distribution\n",
    "        for i in range(num_classes):\n",
    "            #print(f\"i: {i} - proba[:,i]: {(binned_predictions.ravel() == i).astype(float)}\")\n",
    "            proba[:, i] = (binned_predictions.ravel() == i).astype(float)\n",
    "        \n",
    "        # Normalize probabilities row-wise to sum to 1\n",
    "        proba = proba / proba.sum(axis=1, keepdims=True)\n",
    "        \n",
    "        return proba\n",
    "    \n",
    "    def score(self, X, y, sample_weight=None):\n",
    "\n",
    "        # Ensure that the fit was successful\n",
    "        try:\n",
    "            check_is_fitted(self, ['regressor', 'intervals', 'classes_'])\n",
    "        except NotFittedError as exc:\n",
    "            print(\"Model is not fitted yet.\")\n",
    "\n",
    "        # Ensure X is a 2d array (i.e. has 2 axises) and denies sparse data\n",
    "        X = check_array(X, accept_sparse=False, ensure_2d=True)\n",
    "\n",
    "        # Validate and check X and y for consistency,deny sparse X, \n",
    "        X, y = check_X_y(X, y, accept_sparse=False, y_numeric=True, ensure_2d=True)\n",
    "\n",
    "        return self.regressor.score(X, y, sample_weight)\n",
    "\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        #return {\"regressor\": self.regressor, \"intervals\": self.intervals, \"regressor_params\": self.regressor.get_params()}\n",
    "        return {\"regressor\": self.regressor, \"intervals\": self.intervals}\n",
    "\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression(**{\"fit_intercept\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BinningClassifier.__init__() got an unexpected keyword argument 'regressor_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m intervals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m1000\u001b[39m])\n\u001b[0;32m      7\u001b[0m clf \u001b[38;5;241m=\u001b[39m BinningClassifier(regressor\u001b[38;5;241m=\u001b[39mLinearRegression(), intervals\u001b[38;5;241m=\u001b[39mintervals)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mcheck_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hal9\\anaconda3\\envs\\condaPytorchEnv\\lib\\site-packages\\sklearn\\utils\\estimator_checks.py:630\u001b[0m, in \u001b[0;36mcheck_estimator\u001b[1;34m(estimator, generate_only)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m estimator, check \u001b[38;5;129;01min\u001b[39;00m checks_generator():\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 630\u001b[0m         \u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m SkipTest \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;66;03m# SkipTest is thrown when pandas can't be imported, or by checks\u001b[39;00m\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;66;03m# that are in the xfail_checks tag\u001b[39;00m\n\u001b[0;32m    634\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;28mstr\u001b[39m(exception), SkipTestWarning)\n",
      "File \u001b[1;32mc:\\Users\\Hal9\\anaconda3\\envs\\condaPytorchEnv\\lib\\site-packages\\sklearn\\utils\\_testing.py:180\u001b[0m, in \u001b[0;36m_IgnoreWarnings.__call__.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    179\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategory)\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hal9\\anaconda3\\envs\\condaPytorchEnv\\lib\\site-packages\\sklearn\\utils\\estimator_checks.py:3196\u001b[0m, in \u001b[0;36mcheck_no_attributes_set_in_init\u001b[1;34m(name, estimator_orig)\u001b[0m\n\u001b[0;32m   3192\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check setting during init.\"\"\"\u001b[39;00m\n\u001b[0;32m   3193\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   3194\u001b[0m     \u001b[38;5;66;03m# Clone fails if the estimator does not store\u001b[39;00m\n\u001b[0;32m   3195\u001b[0m     \u001b[38;5;66;03m# all parameters as an attribute during init\u001b[39;00m\n\u001b[1;32m-> 3196\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   3198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   3199\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should store all parameters as an attribute during init.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3200\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Hal9\\anaconda3\\envs\\condaPytorchEnv\\lib\\site-packages\\sklearn\\base.py:75\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct a new unfitted estimator with the same parameters.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03mClone does a deep copy of the model in an estimator\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03mfound in :ref:`randomness`.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_clone__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(estimator):\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_clone__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _clone_parametrized(estimator, safe\u001b[38;5;241m=\u001b[39msafe)\n",
      "File \u001b[1;32mc:\\Users\\Hal9\\anaconda3\\envs\\condaPytorchEnv\\lib\\site-packages\\sklearn\\base.py:267\u001b[0m, in \u001b[0;36mBaseEstimator.__sklearn_clone__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sklearn_clone__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_parametrized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hal9\\anaconda3\\envs\\condaPytorchEnv\\lib\\site-packages\\sklearn\\base.py:109\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m new_object_params\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    107\u001b[0m     new_object_params[name] \u001b[38;5;241m=\u001b[39m clone(param, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 109\u001b[0m new_object \u001b[38;5;241m=\u001b[39m klass(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_object_params)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m     new_object\u001b[38;5;241m.\u001b[39m_metadata_request \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(estimator\u001b[38;5;241m.\u001b[39m_metadata_request)\n",
      "\u001b[1;31mTypeError\u001b[0m: BinningClassifier.__init__() got an unexpected keyword argument 'regressor_params'"
     ]
    }
   ],
   "source": [
    "# Adding some debug prints to understand the input shapes:\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.utils.estimator_checks import check_estimator # scikits api-check \n",
    "\n",
    "intervals = np.array([-1000, 10, 15, 20, 25, 30, 1000])\n",
    "clf = BinningClassifier(regressor=LinearRegression(), intervals=intervals)\n",
    "\n",
    "check_estimator(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: [[ 2.01]\n",
      " [ 4.04]\n",
      " [ 6.09]\n",
      " [ 8.16]\n",
      " [10.25]\n",
      " [12.36]\n",
      " [14.49]\n",
      " [16.64]\n",
      " [18.81]]\n",
      "probs: \n",
      " [[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hal9\\anaconda3\\envs\\condaPytorchEnv\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# comment out the init method without kwargs and comment in the init method with kwargs in BinningClassifier and run this example - seems to work -\n",
    "# so the problem obviously lies with the check_estimator...\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([1,2,3,4,5,6,7,8,9]).reshape(-1,1)\n",
    "#X = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]).reshape(-1,1)\n",
    "y = 2 * X + (X * X / 100)\n",
    "\n",
    "print(f\"y: {y}\")\n",
    "\n",
    "intervals = np.array([-1000,1,3,5,7,9,11,13,19, 1000])\n",
    "\n",
    "bsc_clf = BinningClassifier(regressor=LinearRegression(), intervals=intervals, fit_intercept=True)\n",
    "bsc_clf.fit(X,y)\n",
    "preds = bsc_clf.predict(X)\n",
    "#print(f\"preds: {preds}\")\n",
    "probs = bsc_clf.predict_proba(X)\n",
    "print(f\"probs: \\n {probs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regressor: reggi\n",
      "intervals: [0, 4, 8]\n",
      "key: fit_intercept -- value:True\n"
     ]
    }
   ],
   "source": [
    "# test example using kwargs - works as it should:\n",
    "\n",
    "def tt(regressor=None, intervals=None, **regressor_params):\n",
    "    print(f\"regressor: {regressor}\")\n",
    "    print(f\"intervals: {intervals}\")\n",
    "    if(regressor_params):\n",
    "        for k,v in regressor_params.items():\n",
    "            print(f\"key: {k} -- value:{v}\")\n",
    "\n",
    "tt(regressor=\"reggi\", intervals=[0,4,8], fit_intercept=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaPytorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
