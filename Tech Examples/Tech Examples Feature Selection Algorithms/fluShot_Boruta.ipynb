{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flushot Boruta with Multi-Step Column-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv-files and take the respondent_id column as index:\n",
    "\n",
    "X_train_df = pd.read_csv(\"training_set_features.csv\", index_col=\"respondent_id\")\n",
    "y_train_df = pd.read_csv(\"training_set_labels.csv\", index_col=\"respondent_id\")\n",
    "X_test_df = pd.read_csv(\"test_set_features.csv\", index_col=\"respondent_id\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the columns and their data-types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nh1n1_concern : float64\\nh1n1_knowledge : float64\\nbehavioral_antiviral_meds : float64\\nbehavioral_avoidance : float64\\nbehavioral_face_mask : float64\\nbehavioral_wash_hands : float64\\nbehavioral_large_gatherings : float64\\nbehavioral_outside_home : float64\\nbehavioral_touch_face : float64\\ndoctor_recc_h1n1 : float64\\ndoctor_recc_seasonal : float64\\nchronic_med_condition : float64\\nchild_under_6_months : float64\\nhealth_worker : float64\\nhealth_insurance : float64\\nopinion_h1n1_vacc_effective : float64\\nopinion_h1n1_risk : float64\\nopinion_h1n1_sick_from_vacc : float64\\nopinion_seas_vacc_effective : float64\\nopinion_seas_risk : float64\\nopinion_seas_sick_from_vacc : float64\\nage_group : object\\neducation : object\\nrace : object\\nsex : object\\nincome_poverty : object\\nmarital_status : object\\nrent_or_own : object\\nemployment_status : object\\nhhs_geo_region : object\\ncensus_msa : object\\nhousehold_adults : float64\\nhousehold_children : float64\\nemployment_industry : object\\nemployment_occupation : object\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for convenience the code producing the column-name : dtype output of the data-frame is commented out:\n",
    "\n",
    "#for i,t in zip(X_train_df.dtypes.index,X_train_df.dtypes):\n",
    "#    print(f\"{i} : {t}\")\n",
    "\n",
    "# Result:\n",
    "\"\"\" \n",
    "h1n1_concern : float64\n",
    "h1n1_knowledge : float64\n",
    "behavioral_antiviral_meds : float64\n",
    "behavioral_avoidance : float64\n",
    "behavioral_face_mask : float64\n",
    "behavioral_wash_hands : float64\n",
    "behavioral_large_gatherings : float64\n",
    "behavioral_outside_home : float64\n",
    "behavioral_touch_face : float64\n",
    "doctor_recc_h1n1 : float64\n",
    "doctor_recc_seasonal : float64\n",
    "chronic_med_condition : float64\n",
    "child_under_6_months : float64\n",
    "health_worker : float64\n",
    "health_insurance : float64\n",
    "opinion_h1n1_vacc_effective : float64\n",
    "opinion_h1n1_risk : float64\n",
    "opinion_h1n1_sick_from_vacc : float64\n",
    "opinion_seas_vacc_effective : float64\n",
    "opinion_seas_risk : float64\n",
    "opinion_seas_sick_from_vacc : float64\n",
    "age_group : object\n",
    "education : object\n",
    "race : object\n",
    "sex : object\n",
    "income_poverty : object\n",
    "marital_status : object\n",
    "rent_or_own : object\n",
    "employment_status : object\n",
    "hhs_geo_region : object\n",
    "census_msa : object\n",
    "household_adults : float64\n",
    "household_children : float64\n",
    "employment_industry : object\n",
    "employment_occupation : object\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data-types and the meaning of the columns, we select the appropriate transformations to convert data into numeric form."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the columns on which to perform what:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_columns = [\"race\", \"sex\", \"marital_status\", \"rent_or_own\", \"employment_status\", \"hhs_geo_region\", \"census_msa\", \"employment_industry\", \"employment_occupation\"]\n",
    "ordinal_columns = ['age_group','education', 'income_poverty']\n",
    "numeric_columns = X_train_df.columns[X_train_df.dtypes == \"float64\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a Pipeline for multi-step Transformation of a Column-Set:\n",
    "\n",
    "If there is more than one transformation to be executed on one and the same set of columns, like here numeric_columns, then these steps have to be\n",
    "collected inside a Pipeline - it does not work to do these step one after the other directly in the column-transformer, as every step will augment the data-frame with columns containing the result of the transformation-step - which could be expected, since a ColumnTransformer is not a pipeline, i.e. does not know anything about first-step, second-step, third-step..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline([\n",
    "    (\"SimpleImputer\", SimpleImputer(strategy=\"median\", missing_values=np.nan)),\n",
    "    (\"PostImp_StandardScaler\", StandardScaler(copy=False))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Column-Transformer: <br>\n",
    "<br>\n",
    "We will use a one-hot-encoder on the data-frame before we will send the data to the column-transformer, but we can allready define the column-transformer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "full_columnTransformer = ColumnTransformer(\n",
    "    transformers= [\n",
    "        (\"numerical_pipeline\", num_pipe, numeric_columns),\n",
    "        (\"ordinal_preprocessing\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1, encoded_missing_value=-1), ordinal_columns),\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot-encoding the training- and the test-data: <br>\n",
    "We print out the shape of the data-frame to see if something happend with the data-frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_df.shape: (26707, 35)\n",
      "X_train_df.shape: (26707, 105)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_df.shape: {X_train_df.shape}\")\n",
    "X_train_df = pd.get_dummies(data=X_train_df, columns=ohe_columns, dummy_na=True)\n",
    "print(f\"X_train_df.shape: {X_train_df.shape}\")\n",
    "X_test_df = pd.get_dummies(data=X_test_df, columns=ohe_columns, dummy_na=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously some columns have been added to the data-frame under the one-hot-encoding..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the column-names of the data-frame to because the column-transformer will only return a numpy-array and we might re-construct our pandas data-frame from this later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dfnp.shape: (26707, 105)\n",
      "X_train_df.shape: (26707, 105)\n"
     ]
    }
   ],
   "source": [
    "X_columns = X_train_df.columns # contains the columns including those after one-hot-encoding\n",
    "\n",
    "X_train_dfnp = full_columnTransformer.fit_transform(X_train_df)\n",
    "X_test_dfnp = full_columnTransformer.transform(X_test_df)\n",
    "print(f\"X_train_dfnp.shape: {X_train_dfnp.shape}\")\n",
    "print(f\"X_train_df.shape: {X_train_df.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all missing values have been removed by imputation and ordinal-encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(X_train_dfnp).sum().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the multi-lable classification values to single lable:\n",
    "\n",
    "The multiclass labels have to be encoded as single class labels, because the Boruta Algorithm expects a 1d array as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26707,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the multi-lable classification values to single lable:\n",
    "\n",
    "singleY={\"[0 0]\": 0, \"[0 1]\": 1, \"[1 0]\":2, \"[1 1]\": 3}\n",
    "y_train_single = np.array([singleY[str(y)] for y in y_train_df.values])\n",
    "y_train_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26707, 105)\n",
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t105\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t105\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t105\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t105\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t105\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t105\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t105\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t3\n",
      "Rejected: \t56\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t3\n",
      "Rejected: \t56\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t3\n",
      "Rejected: \t56\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t3\n",
      "Rejected: \t56\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t3\n",
      "Rejected: \t56\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t3\n",
      "Rejected: \t56\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t2\n",
      "Rejected: \t57\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t2\n",
      "Rejected: \t57\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t2\n",
      "Rejected: \t57\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t2\n",
      "Rejected: \t57\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t2\n",
      "Rejected: \t57\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t2\n",
      "Rejected: \t57\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t2\n",
      "Rejected: \t57\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t2\n",
      "Rejected: \t57\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t2\n",
      "Rejected: \t57\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t2\n",
      "Rejected: \t57\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t2\n",
      "Rejected: \t57\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t2\n",
      "Rejected: \t57\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t2\n",
      "Rejected: \t57\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t1\n",
      "Rejected: \t58\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t1\n",
      "Rejected: \t58\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t1\n",
      "Rejected: \t58\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t1\n",
      "Rejected: \t58\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t1\n",
      "Rejected: \t58\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t1\n",
      "Rejected: \t58\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t1\n",
      "Rejected: \t58\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t1\n",
      "Rejected: \t58\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t0\n",
      "Rejected: \t59\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t0\n",
      "Rejected: \t59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BorutaPy(estimator=RandomForestClassifier(max_depth=5, n_estimators=1000,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x2903BB94640),\n",
       "         random_state=RandomState(MT19937) at 0x2903BB94640, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BorutaPy</label><div class=\"sk-toggleable__content\"><pre>BorutaPy(estimator=RandomForestClassifier(max_depth=5, n_estimators=1000,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x2903BB94640),\n",
       "         random_state=RandomState(MT19937) at 0x2903BB94640, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, n_estimators=1000, n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x2903BB94640)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, n_estimators=1000, n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x2903BB94640)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(max_depth=5, n_estimators=1000,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x2903BB94640),\n",
       "         random_state=RandomState(MT19937) at 0x2903BB94640, verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=200, n_jobs=-1, max_depth=5)\n",
    "\n",
    "boruta_selector = BorutaPy(clf, random_state=42, verbose=2)\n",
    "#sel = boruta_selector.fit_transform(X_train_dfnp, y_train_single)\n",
    "print(X_train_dfnp.shape)\n",
    "boruta_selector.fit(X_train_dfnp, y_train_single)\n",
    "\n",
    "# time: 46.4s - \n",
    "# time - when all columns are ordinal encoded: 2m8.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranks of the features: [ 1  1  9  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1 22  1 58  1  1 58  1  1  6  1  1  8  1  1  1  4 29 10 34 20\n",
      " 26 24  7 28 13 35 58 14 25 17 58 32 23 48 50  1  1 20 42 44 54 37 55  5\n",
      " 56  1 17 12 49 14  1 19  1 41 44  1  1 46 30 17 37 52 46 35 32 53  1 39\n",
      " 10 39  3 43  2 30 27 51  1]\n",
      "Boruta proposed selection of features: [ True  True False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True False  True False  True  True False  True  True\n",
      " False  True  True False  True  True  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True  True False False False False False False False\n",
      " False  True False False False False  True False  True False False  True\n",
      "  True False False False False False False False False False  True False\n",
      " False False False False False False False False  True]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ranks of the features: {boruta_selector.ranking_}\")\n",
    "print(f\"Boruta proposed selection of features: {boruta_selector.support_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Boruta ranking we retain 46 features from 105\n"
     ]
    }
   ],
   "source": [
    "# keep only the columns that have ranking==1:\n",
    "X_train_df_boruta = boruta_selector.transform(X_train_dfnp)\n",
    "X_columns_boruta = X_columns[boruta_selector.support_]\n",
    "X_test_df_boruta = boruta_selector.transform(X_test_dfnp)\n",
    "print(f\"With Boruta ranking we retain {X_train_df_boruta.shape[1]} features from {X_train_dfnp.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['h1n1_concern', 'h1n1_knowledge', 'behavioral_avoidance',\n",
       "       'behavioral_face_mask', 'behavioral_wash_hands',\n",
       "       'behavioral_large_gatherings', 'behavioral_outside_home',\n",
       "       'behavioral_touch_face', 'doctor_recc_h1n1', 'doctor_recc_seasonal',\n",
       "       'chronic_med_condition', 'child_under_6_months', 'health_worker',\n",
       "       'health_insurance', 'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk',\n",
       "       'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective',\n",
       "       'opinion_seas_risk', 'opinion_seas_sick_from_vacc', 'age_group',\n",
       "       'education', 'income_poverty', 'household_adults', 'household_children',\n",
       "       'race_Black', 'race_Hispanic', 'race_White', 'sex_Female', 'sex_Male',\n",
       "       'marital_status_Married', 'marital_status_Not Married',\n",
       "       'rent_or_own_Own', 'rent_or_own_Rent', 'employment_status_Employed',\n",
       "       'employment_status_Not in Labor Force', 'employment_status_Unemployed',\n",
       "       'employment_industry_fcxhlnwr', 'employment_industry_haxffmxo',\n",
       "       'employment_industry_rucpziij', 'employment_industry_xicduogh',\n",
       "       'employment_industry_nan', 'employment_occupation_cmhcxjea',\n",
       "       'employment_occupation_dcjcmpih', 'employment_occupation_qxajmpny',\n",
       "       'employment_occupation_nan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_columns_boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the boruta-selected data:\n",
    "X_train_Boruta_df = pd.DataFrame(X_train_df_boruta, columns=X_columns_boruta)\n",
    "X_train_Boruta_df.to_csv(\"X_train_Boruta_df.csv\", index_label=\"respondent_id\")\n",
    "X_test_Boruta_df = pd.DataFrame(X_test_df_boruta, columns=X_columns_boruta)\n",
    "X_test_Boruta_df.to_csv(\"X_test_Boruta_df.csv\", index_label=\"respondent_id\")\n",
    "\n",
    "XB_train, XB_eval, yb_train, yb_eval = train_test_split(X_train_Boruta_df, y_train_single, test_size=0.33, shuffle=True, stratify=y_train_single, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hal9\\anaconda3\\envs\\condaPytorchEnv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6786929884275017"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42 ,penalty=\"l2\", C=1)\n",
    "clf.fit(XB_train, yb_train)\n",
    "clf.score(XB_eval, yb_eval)\n",
    "# Result:\n",
    "# 0.6786929884275017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# make your own selection, which columns to keep:\n",
    "\n",
    "# select the first features with rank <= max_rank:\n",
    "\n",
    "\n",
    "def get_boruta_selected_features(max_rank, df, boruta_ranking):\n",
    "    \"\"\"select the first features with Boruta-rank <= max_rank\n",
    "    return these features of df as a pandas dataframe\n",
    "    \"\"\"\n",
    "    features_df = pd.DataFrame(df.columns, columns=['feature'])\n",
    "    features_df['rank']= boruta_ranking\n",
    "    features_df.sort_values('rank', inplace=True, ascending=True)\n",
    "\n",
    "    # selection:\n",
    "    selected = features_df[features_df[\"rank\"] <= max_rank]\n",
    "    return df[selected[\"feature\"].values]\n",
    "\n",
    "rank = 2\n",
    "db = get_boruta_selected_features(max_rank=rank, df=X_train_dfnp, boruta_ranking= boruta_selector.ranking_)\n",
    "db.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# save the boruta-selected data:\n",
    "X_trainB_df = get_boruta_selected_features(max_rank=1, df=X_train_df, boruta_ranking= boruta_selector.ranking_)\n",
    "X_trainB_df.to_csv(\"X_train_df_boruta.csv\", index_label=\"respondent_id\")\n",
    "X_testB_df = get_boruta_selected_features(max_rank=1, df=X_test_df, boruta_ranking= boruta_selector.ranking_)\n",
    "X_testB_df.to_csv(\"X_test_df_boruta.csv\", index_label=\"respondent_id\")\n",
    "\n",
    "XB_train, XB_eval, yb_train, yb_eval = train_test_split(X_trainB_df, y_train_single, test_size=0.33, shuffle=True, stratify=y_train_single, random_state=42)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaPytorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df61620949cb14e55b843831dad5e2bfed0f7347786fc0c0d43a7e8bd69fd61c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
