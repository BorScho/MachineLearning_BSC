{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV on Sklearn's MultiOutputClassifier ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the run-times of this solution, where we use the Sklearn MultiOutputClassifier and apply GridSearchCV to it, with the run-times of the solution above, where we transform the multiclass-labels to four categories, train a pipeline containing a gridsearch:\n",
    "\n",
    "Training: this = 0.8s, above = 1m53,3s\n",
    "\n",
    "Retraining on full set: this = 1.2s , above = 2m20.5s\n",
    "\n",
    "Maybe the gridsearch in the pipeline is time consuming and it should rather be a pipeline in the gridsearch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hal9\\anaconda3\\envs\\condaPytorchEnv\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "c:\\Users\\Hal9\\anaconda3\\envs\\condaPytorchEnv\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import auxiliaries as aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and Train-Test Split Data ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv-files and take the respondent_id column as index:\n",
    "\n",
    "X_train_df = pd.read_csv(\"training_set_features.csv\", index_col=\"respondent_id\")\n",
    "y_train_df = pd.read_csv(\"training_set_labels.csv\", index_col=\"respondent_id\")\n",
    "X_test_df = pd.read_csv(\"test_set_features.csv\", index_col=\"respondent_id\")\n",
    "\n",
    "X_train_df.shape, X_test_df.shape\n",
    "# Output:\n",
    "# ((26707, 36), (26708, 36))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 11\n",
    "test_size = 0.2\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X_train_df, y_train_df, test_size=test_size, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing Pipeline ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X_train_df.columns[X_train_df.dtypes != \"object\"].values\n",
    "non_numeric_columns = X_train_df.columns[X_train_df.dtypes == \"object\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepro pipeline for the numeric columns (we drop the non-numeric columns):\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# impute the most frequent value:\n",
    "impute_most_frequent_numeric = Pipeline([\n",
    "    (\"most_frequent_imputer\", SimpleImputer(strategy=\"most_frequent\"))\n",
    "    ])\n",
    "\n",
    "\n",
    "# column transformer with only numerical columns:\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"numeric\", impute_most_frequent_numeric, num_cols),\n",
    "        (\"ohe_num\", OneHotEncoder(), num_cols),\n",
    "        (\"ohe_non_num\", OneHotEncoder(), non_numeric_columns)\n",
    "    ],\n",
    "    remainder=\"drop\" # drop all non-numeric columns from the data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid-search for the multioutput-classifier as a whole:\n",
    "\n",
    "\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric=\"error\")\n",
    "multioutput_model = MultiOutputClassifier(model)\n",
    "\n",
    "multi_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"multioutput_clf\", multioutput_model),\n",
    "])\n",
    "\n",
    "max_depth = [2, 4, 8]\n",
    "n_estimators = [100, 200, 400, 800]\n",
    "\n",
    "\n",
    "gridcv_params = dict(max_depth=max_depth, n_estimators=n_estimators)\n",
    "\n",
    "grid_search = GridSearchCV(multi_pipeline, param_grid=gridcv_params, scoring=\"roc_auc\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model and Plot Results ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "#print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = multi_pipeline.predict_proba(X_eval)\n",
    "\n",
    "# probabilities for the two categories:\n",
    "y_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peek at data-structure:\n",
    "\n",
    "y_eval.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_true = true_preds(y_preds, y_eval.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.plot_roc_h1n1_and_seasonal(y_eval, y_preds_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Submission-File ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to \"my_submission_file\":\n",
    "\n",
    "my_submission_file = \"my_submission_MultiOutputClassifier_xgboost.csv\"\n",
    "\n",
    "aux.train_fullset_and_save(multi_pipeline, X_test_df, X_train_df, y_train_df, my_submission_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation of dmlc XGBoost / py-xgboost(?)\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/python/python_intro.html#setting-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()\n",
    "\n",
    "# output:\n",
    "#{'objective': 'multi:softprob',\n",
    "# 'use_label_encoder': False,\n",
    "# 'base_score': 0.5,\n",
    "# 'booster': 'gbtree',\n",
    "# 'colsample_bylevel': 1,\n",
    "# 'colsample_bynode': 1,\n",
    "# 'colsample_bytree': 1,\n",
    "# 'enable_categorical': False,\n",
    "# 'gamma': 0,\n",
    "# 'gpu_id': -1,\n",
    "# 'importance_type': None,\n",
    "# 'interaction_constraints': '',\n",
    "# 'learning_rate': 0.300000012,\n",
    "# 'max_delta_step': 0,\n",
    "# 'max_depth': 6,\n",
    "# 'min_child_weight': 1,\n",
    "# 'missing': nan,\n",
    "# 'monotone_constraints': '()',\n",
    "# 'n_estimators': 100,\n",
    "# 'n_jobs': 24,\n",
    "# 'num_parallel_tree': 1,\n",
    "# 'predictor': 'auto',\n",
    "# 'random_state': 0,\n",
    "# 'reg_alpha': 0,\n",
    "# 'reg_lambda': 1,\n",
    "# 'scale_pos_weight': None,\n",
    "# 'subsample': 1,\n",
    "# 'tree_method': 'exact',\n",
    "# 'validate_parameters': 1,\n",
    "# 'verbosity': None}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('condaPytorchEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df61620949cb14e55b843831dad5e2bfed0f7347786fc0c0d43a7e8bd69fd61c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
