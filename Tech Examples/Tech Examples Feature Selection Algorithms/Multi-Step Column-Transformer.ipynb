{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Step Column-Transformer\n",
    "This notebook shows how to use a pipeline inside a column-transformer in order to be able to make column transformations which require more than one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv-files and take the respondent_id column as index:\n",
    "\n",
    "X_train_df = pd.read_csv(\"training_set_features.csv\", index_col=\"respondent_id\")\n",
    "y_train_df = pd.read_csv(\"training_set_labels.csv\", index_col=\"respondent_id\")\n",
    "X_test_df = pd.read_csv(\"test_set_features.csv\", index_col=\"respondent_id\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the columns and their data-types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nh1n1_concern : float64\\nh1n1_knowledge : float64\\nbehavioral_antiviral_meds : float64\\nbehavioral_avoidance : float64\\nbehavioral_face_mask : float64\\nbehavioral_wash_hands : float64\\nbehavioral_large_gatherings : float64\\nbehavioral_outside_home : float64\\nbehavioral_touch_face : float64\\ndoctor_recc_h1n1 : float64\\ndoctor_recc_seasonal : float64\\nchronic_med_condition : float64\\nchild_under_6_months : float64\\nhealth_worker : float64\\nhealth_insurance : float64\\nopinion_h1n1_vacc_effective : float64\\nopinion_h1n1_risk : float64\\nopinion_h1n1_sick_from_vacc : float64\\nopinion_seas_vacc_effective : float64\\nopinion_seas_risk : float64\\nopinion_seas_sick_from_vacc : float64\\nage_group : object\\neducation : object\\nrace : object\\nsex : object\\nincome_poverty : object\\nmarital_status : object\\nrent_or_own : object\\nemployment_status : object\\nhhs_geo_region : object\\ncensus_msa : object\\nhousehold_adults : float64\\nhousehold_children : float64\\nemployment_industry : object\\nemployment_occupation : object\\n\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for convenience the code producing the column-name : dtype output of the data-frame is commented out:\n",
    "\n",
    "#for i,t in zip(X_train_df.dtypes.index,X_train_df.dtypes):\n",
    "#    print(f\"{i} : {t}\")\n",
    "\n",
    "# Result:\n",
    "\"\"\" \n",
    "h1n1_concern : float64\n",
    "h1n1_knowledge : float64\n",
    "behavioral_antiviral_meds : float64\n",
    "behavioral_avoidance : float64\n",
    "behavioral_face_mask : float64\n",
    "behavioral_wash_hands : float64\n",
    "behavioral_large_gatherings : float64\n",
    "behavioral_outside_home : float64\n",
    "behavioral_touch_face : float64\n",
    "doctor_recc_h1n1 : float64\n",
    "doctor_recc_seasonal : float64\n",
    "chronic_med_condition : float64\n",
    "child_under_6_months : float64\n",
    "health_worker : float64\n",
    "health_insurance : float64\n",
    "opinion_h1n1_vacc_effective : float64\n",
    "opinion_h1n1_risk : float64\n",
    "opinion_h1n1_sick_from_vacc : float64\n",
    "opinion_seas_vacc_effective : float64\n",
    "opinion_seas_risk : float64\n",
    "opinion_seas_sick_from_vacc : float64\n",
    "age_group : object\n",
    "education : object\n",
    "race : object\n",
    "sex : object\n",
    "income_poverty : object\n",
    "marital_status : object\n",
    "rent_or_own : object\n",
    "employment_status : object\n",
    "hhs_geo_region : object\n",
    "census_msa : object\n",
    "household_adults : float64\n",
    "household_children : float64\n",
    "employment_industry : object\n",
    "employment_occupation : object\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data-types and the meaning of the columns, we select the appropriate transformations to convert data into numeric form."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the columns on which to perform what:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_columns = [\"race\", \"sex\", \"marital_status\", \"rent_or_own\", \"employment_status\", \"hhs_geo_region\", \"census_msa\", \"employment_industry\", \"employment_occupation\"]\n",
    "ordinal_columns = ['age_group','education', 'income_poverty']\n",
    "numeric_columns = X_train_df.columns[X_train_df.dtypes == \"float64\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a Pipeline for multi-step Transformation of a Column-Set:\n",
    "\n",
    "If there is more than one transformation to be executed on one and the same set of columns, like here numeric_columns, then these steps have to be\n",
    "collected inside a Pipeline - it does not work to do these step one after the other directly in the column-transformer, as every step will augment the data-frame with columns containing the result of the transformation-step - which could be expected, since a ColumnTransformer is not a pipeline, i.e. does not know anything about first-step, second-step, third-step..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline([\n",
    "    (\"SimpleImputer\", SimpleImputer(strategy=\"median\", missing_values=np.nan)),\n",
    "    (\"PostImp_StandardScaler\", StandardScaler(copy=False))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Column-Transformer: <br>\n",
    "<br>\n",
    "We will use a one-hot-encoder on the data-frame before we will send the data to the column-transformer, but we can allready define the column-transformer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "full_columnTransformer = ColumnTransformer(\n",
    "    transformers= [\n",
    "        (\"numerical_pipeline\", num_pipe, numeric_columns),\n",
    "        (\"ordinal_preprocessing\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1, encoded_missing_value=-1), ordinal_columns),\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot-encoding the training- and the test-data: <br>\n",
    "We print out the shape of the data-frame to see if something happend with the data-frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_df.shape: (26707, 35)\n",
      "X_train_df.shape: (26707, 105)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_df.shape: {X_train_df.shape}\")\n",
    "X_train_df = pd.get_dummies(data=X_train_df, columns=ohe_columns, dummy_na=True)\n",
    "print(f\"X_train_df.shape: {X_train_df.shape}\")\n",
    "X_test_df = pd.get_dummies(data=X_test_df, columns=ohe_columns, dummy_na=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously some columns have been added to the data-frame under the one-hot-encoding..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the column-names of the data-frame to because the column-transformer will only return a numpy-array and we might re-construct our pandas data-frame from this later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dfnp.shape: (26707, 105)\n",
      "X_train_df.shape: (26707, 105)\n"
     ]
    }
   ],
   "source": [
    "X_columns = X_train_df.columns\n",
    "\n",
    "X_train_dfnp = full_columnTransformer.fit_transform(X_train_df)\n",
    "X_test_dfnp = full_columnTransformer.transform(X_test_df)\n",
    "print(f\"X_train_dfnp.shape: {X_train_dfnp.shape}\")\n",
    "print(f\"X_train_df.shape: {X_train_df.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all missing values have been removed by imputation and ordinal-encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(X_train_dfnp).sum().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaPytorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df61620949cb14e55b843831dad5e2bfed0f7347786fc0c0d43a7e8bd69fd61c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
